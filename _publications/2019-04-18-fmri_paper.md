---
title: "New fMRI Paper: Distinct Representation of Locomotive Affordances in Brains and Models"
date: 2024-07-14
layout: single
categories:
  - research
tags:
  - publication
  - neuroscience
  - fMRI
  - affordances
  - scene perception
  - deep learning
excerpt: "Our fMRI and behavioral study reveals that human visual cortex distinctly represents locomotive affordances in scenesâ€”beyond what current DNNs can model."
image:
  path: /home/clemens-uva/cgbartnik.github.io/assets/images/mountain_range_blurry.png
  alt: "Thumbnail of fMRI study on action affordances"
header:
  overlay_image: /home/clemens-uva/cgbartnik.github.io/assets/images/mountain_range_blurry.png
  caption: "Bartnik et al. (2024) â€” Affordance Representations in Brain and AI"
  overlay_filter: 0.3
  actions:
    - label: "Read Abstract"
      url: "https://doi.org/10.1101/2024.05.15.594298"
    - label: "Download PDF"
      url: "/assets/papers/2024-bartnik-affordances-fmri.pdf"
---

In this new fMRI study, we show that **scene-selective areas of the brain â€” PPA and OPA â€” distinctly represent locomotive action affordances**, such as walking, biking, or swimming, based on visual input alone.

We combined **behavioral ratings**, **multi-voxel fMRI data**, and **deep neural network (DNN) models** to investigate how humans perceive the ways they can move through a scene â€” and how this compares to computational models.


<p align="center">
  <img src="/assets/images/fmri_website_image.png" alt="Overview of scene perception approaches" width="800"><br>
  <em>Overview of object-, space-, and affordance-centered approaches to scene perception.</em>
</p>


ðŸ§  **Key finding**: Human visual cortex encodes affordances in a **task-independent** and **distinct way**, not explained by scene objects or materials alone.

ðŸ¤– **DNNs fall short**: Popular deep models trained on object or scene recognition (including CLIP and ViTs) could only **partially explain** human representations. However, **multimodal models like GPT-4**, when prompted appropriately, show promise in better aligning with human behavior.

ðŸ”— [Read the abstract on bioRxiv](https://doi.org/10.1101/2024.05.15.594298)  
ðŸ“„ [Download the PDF](/assets/papers/2024-bartnik-affordances-fmri.pdf)

---

This work expands our understanding of **affordance perception** and lays the groundwork for **more human-aligned visual AI models**.



