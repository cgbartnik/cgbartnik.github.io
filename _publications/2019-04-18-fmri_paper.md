---
title: "Representation of Locomotive Affordances in Brains and Models"
date: 2024-07-14
layout: single
categories:
  - research
tags:
  - publication
  - neuroscience
  - fMRI
  - affordances
  - scene perception
  - deep learning
excerpt: "Our fMRI and behavioral study, published in PNAS, reveals that human visual cortex distinctly represents locomotive affordances in scenes—beyond what current DNNs can model."
image:
  path: assets/images/michael-olsen-YWxfEBlvoiI-unsplash.jpg
  alt: "Thumbnail of fMRI study on action affordances"
header:
  overlay_image: assets/images/michael-olsen-YWxfEBlvoiI-unsplash.jpg
  caption: "Photo by Michael Olsen on Unsplash"
  overlay_filter: 0.5
  actions:
    - label: "View Paper"
      url: "https://doi.org/10.1073/pnas.2414005122"
    - label: "Download PDF"
      url: "/assets/papers/2024-bartnik-affordances-fmri.pdf"
---

# Chapter 3: Representation of locomotive action affordances in human behavior, brains and deep neural networks  

**Published as:**  
Bartnik, C. G., Sartzetaki, C., Puigseslloses Sanchez, A., Molenkamp, E., Bommer, S., Vukšić, N., & Groen, I. I. A. (2024). *Distinct representation of locomotive action affordances in human behavior, brains and deep neural networks.* *Proceedings of the National Academy of Sciences (PNAS).*  
Published in PNAS: [PNAS, 2024](https://doi.org/10.1073/pnas.2414005122)  

This study was also featured in a press release from the University of Amsterdam:  
[What the human brain can do that AI can’t](https://www.uva.nl/en/content/news/press-releases/2025/06/what-the-human-brain-can-do-that-ai-cant.html)  

---

## Overview  
Building on the affordance-centered framework and our prior review (Chapter 2), this fMRI study investigates how the brain represents locomotive action affordances—such as walking, climbing, or swimming—in complex real-world scenes.  

Using behavioral ratings, multi-voxel fMRI data, and deep neural network (DNN) models, we show that scene-selective regions, particularly the Occipital Place Area (OPA) and Parahippocampal Place Area (PPA), encode affordances independently of other visual scene features.  

These results provide the first clear evidence for locomotive action affordance perception, reinforcing the role of OPA, revealing PPA as an additional key region, and demonstrating that affordances are encoded distinctly from objects and spatial layout in the brain.  

---

<p align="center">
  <img src="/assets/images/fmri_website_image.png" alt="fMRI overview of affordance representations" width="1000"><br>
  <em>fMRI reveals distinct affordance representations in OPA and PPA, beyond objects and spatial layout.</em>
</p>

## Why this matters  
When we look at a scene—whether a staircase, a street, or a swimming pool—the brain does more than recognize objects and surfaces. It also evaluates how we can move through it. These action possibilities, or affordances, are fundamental for guiding behavior.  

Our findings show that the brain contains specialized mechanisms for affordance perception—mechanisms that current AI models only capture partially. This opens new questions about how to build more human-aligned AI systems that understand environments not only in terms of what is in them, but also in terms of what can be done in them.  

---

## Highlights from research  
- fMRI reveals that both OPA and PPA encode locomotive affordances, each making distinct and complementary contributions.  
- Affordances are represented independently of object identity or low-level visual features.  
- Current DNNs capture some aspects of affordance structure, but none fully align with human behavior. Training on affordance labels or using affordance-focused language embeddings improves alignment, but important gaps remain.  


---

[Read the preprint on bioRxiv](https://doi.org/10.1101/2024.05.15.594298)  
[Download the PDF](/assets/papers/2024-bartnik-affordances-fmri.pdf)  
[Read the UvA press release](https://www.uva.nl/en/content/news/press-releases/2025/06/what-the-human-brain-can-do-that-ai-cant.html)  
