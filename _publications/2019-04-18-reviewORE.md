---
title: "Visual perception in the human brain"
date: 2023-11-01
layout: single
categories:
  - research
tags:
  - publication
  - neuroscience
  - scene perception
  - review
  - ORE
excerpt: "Our new review paper on scene perception just came out in the Oxford Research Encyclopedia of Neuroscience."
image:
  path: assets/images/pawel-czerwinski-beBBYVJ_4MM-unsplash.jpg
  alt: "Scene perception paper thumbnail"
header:
  overlay_image: assets/images/pawel-czerwinski-beBBYVJ_4MM-unsplash.jpg
  caption: "Photo by Pawel Czerwinski on Unsplash"
  overlay_filter: 0.5
  teaser: /assets/images/ORE_new.png
  
  actions:
    - label: "View Paper"
      url: "https://oxfordre.com/neuroscience/display/10.1093/acrefore/9780190264086.001.0001/acrefore-9780190264086-e-437"
    - label: "Download PDF"
      url: "https://drive.google.com/file/d/1N4FRxjuFOj5uQFdtUUocxdrKlwv_SqFN/view?usp=sharing"
---

# Visual perception in the human brain: How the brain perceives and understands real-world scenes  

**Published as:**  
Bartnik, C.G. & Groen, I.I.A. (2023). *Visual Perception in the Human Brain: How the Brain Perceives and Understands Real-World Scenes.* *Oxford Research Encyclopedia of Neuroscience.*  
[https://doi.org/10.1093/acrefore/9780190264086.013.437](https://doi.org/10.1093/acrefore/9780190264086.013.437)  

---

## Overview  
This review examines how the human brain perceives and understands real-world visual scenes, emphasizing that this process can be studied through three major theoretical frameworks‚Äî**object-centered**, **space-centered**, and **affordance-centered**‚Äîeach focusing on distinct aspects of scene information.  

It highlights how the discovery of **scene-selective regions** in the visual system has advanced our understanding of scene representation, drawing on **fMRI** studies that show these regions encode multiple types of information, and **EEG/MEG** research that reveals the rapid time course of feature extraction and its link to scene perception behavior.  

The review concludes by identifying key open questions and suggesting that **deep neural networks** offer a promising tool for uncovering the computational mechanisms underlying affordance-based scene representations in the human brain.  

---

<p align="center">
  <img src="/assets/images/ORE_overview.png" alt="Overview of scene perception approaches" width="1200"><br>
  <em>Overview of object-, space-, and affordance-centered approaches to scene perception.</em>
</p>



## Why this matters  
Perceiving the world feels effortless and natural. When looking out the window, one might recognize the university campus or a backyard when working from home. This perceptual experience is both unified and multifaceted: the view of the world forms a scene that is perceived as a coherent whole, associated with diverse experiences.  

Humans recognize objects, perceive surfaces and textures, and ‚Äî crucially ‚Äî possibilities to move around. But the big question is: **How does the brain construct these rich mental representations of the visual environment?**  

In sum, constituent objects, defining surfaces, and the way and scale at which humans interact with an environment are all relevant aspects that make a view a *scene*. Research across neuroscience, psychology, and computer science converges on three complementary perspectives: object-centered, space-centered, and affordance-centered.  

By reviewing these three perspectives, I show how current research has advanced our understanding of scene perception and why the affordance-centered approach may hold the key to future discoveries.  

---

## Highlights from research  
- **fMRI studies** have revealed three scene-selective regions in the brain (PPA, OPA, and RSC) that are key to how we perceive scenes. These regions go beyond recognizing objects and surfaces ‚Äî they also capture the possibilities for action, or **affordances**, that our environments offer.  
- **EEG/MEG studies** show that within just 100‚Äì200 milliseconds, the brain already encodes global properties and scene-relevant features. There are also hints that affordances are computed rapidly, but it is not yet clear whether they arise early or later in processing.  
- **Computational modeling** with deep neural networks demonstrates that networks trained on scene tasks can predict neural activity, while **generative models** (like diffusion models) now allow us to synthesize ‚Äúbrain-preferred‚Äù images, opening new avenues for probing how scenes are represented.  

---

Together, this work suggests that **affordances may be a key to understanding scene perception** ‚Äî and that **AI offers powerful new tools** to explore this frontier.  

üîó [Read it online at Oxford Research Encyclopedia](https://oxfordre.com/neuroscience/display/10.1093/acrefore/9780190264086.001.0001/acrefore-9780190264086-e-437)  
üìÑ [Download PDF](https://drive.google.com/file/d/1N4FRxjuFOj5uQFdtUUocxdrKlwv_SqFN/view?usp=sharing)  
