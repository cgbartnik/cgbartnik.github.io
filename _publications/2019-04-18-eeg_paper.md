---
title: "Temporal Misalignment in Affordance Perception"
date: 2025-03-15
layout: single
categories:
  - research
tags:
  - publication
  - neuroscience
  - EEG
  - affordances
  - scene perception
excerpt: "Our EEG study investigates how the human brain and deep neural networks differ in processing locomotive action affordances in visual scenes."
image:
  path: assets/images/kiko-camaclang-9JQ9aLoVh1s-unsplash.jpg
  alt: "EEG study thumbnail"
header:
  overlay_image: assets/images/kiko-camaclang-9JQ9aLoVh1s-unsplash.jpg
  caption: "Photo by Kiko Camaclang on Unsplash"
  overlay_filter: 0.3
  teaser: /assets/images/CCN_new.png
  actions:
    - label: "View paper"
      url: "https://openreview.net/pdf?id=6FvgJHC4dq"
---

# Temporal misalignment in scene perception: Divergent representations of locomotive action affordances in human brain responses and DNNs  

**Published as:**  
Bartnik, C.G., Fraats, E.I.C. & Groen, I.I.A. (2025). *Temporal misalignment in scene perception: Divergent representations of locomotive action affordances in human brain responses and DNNs.* *Proceedings of Cognitive Computational Neuroscience.*  

---

## Overview  
In this EEG study, we investigated the **temporal dynamics of locomotive action affordances** â€” such as walking, biking, or swimming â€” and how they unfold compared to objects and low-level visual features.  

By combining **time-resolved representational similarity analysis**, **spatiotemporal fusion with fMRI data**, and comparisons to **deep neural networks (DNNs)**, we mapped out how these different sources of information emerge in the brain.  

Our results show that affordance representations appear rapidly â€” **within 200 ms of visual processing** â€” and are distinct from both objects and low-level features like GIST. We further found that both the **Occipital Place Area (OPA)** and **Parahippocampal Place Area (PPA)** contribute, but in a **temporal hierarchy**: OPA engages earlier, while PPA contributes later.  

<p align="center">
  <img src="/assets/images/EEG_overview.png" alt="EEG overview of affordance dynamics" width="900"><br>
  <em>Spatiotemporal dynamics of affordance representations in the brain compared to DNNs.</em>
</p>

---

## Why this matters  
When you glance at a street, a forest path, or a swimming pool, your brain doesnâ€™t just register objects or textures â€” it almost instantly evaluates how you could move through the scene. These **action possibilities (affordances)** are fundamental for guiding navigation and behavior.  

Understanding *when* and *where* affordances emerge in the brain helps bridge the gap between perception and action, and highlights why **current AI models** â€” despite aligning well with early visual signals â€” still fail to capture this crucial aspect of human scene understanding.  

---

## Highlights from research  
-  **Rapid affordance signals**: EEG shows locomotive affordances emerge within ~200 ms, distinct from objects and low-level features.  
-  **OPA vs. PPA**: Spatiotemporal fusion reveals a hierarchy â€” OPA contributes earlier, PPA later, together shaping affordance perception.  
-  **AI misalignment**: Pre-trained DNNs capture early signals but fail to account for affordance-specific dynamics, replicating earlier fMRI findings with a new modality.  

---

Together, these results point to a **temporal signature of affordance processing** in the human brain â€” and underline the need for more **embodied and action-aware AI models** that can move beyond objects and textures to capture the ways humans actually experience their environment.  

ðŸ”— [View the paper on OpenReview](https://openreview.net/pdf?id=6FvgJHC4dq)  
